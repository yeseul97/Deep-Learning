{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3) (25, 1)\n"
     ]
    }
   ],
   "source": [
    "# 05_scores_linear_regression\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.random.set_seed(5)\n",
    "\n",
    "xy = np.loadtxt('data-02-test-score.csv',delimiter=',',\n",
    "                skiprows=1,dtype=np.float32)\n",
    "x_train = xy[:,:-1]  # X\n",
    "y_train = xy[:,[-1]]  # (행렬의 곱셈이므로) 괄호를 이용해 차원을 높여줌\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'weight:0' shape=(3, 1) dtype=float32, numpy=\n",
       "array([[-0.18030666],\n",
       "       [-0.95028627],\n",
       "       [-0.03964049]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변수 초기화 : weight, bias\n",
    "# (m,n) * (n,l)  = (m,l)  , 행렬의 내적 곱셈 공식\n",
    "# (25,3) * (3,1)  = (25,1)\n",
    "\n",
    "W = tf.Variable(tf.random.normal([3,1]), name ='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name = 'bias')\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis 예측 함수 : H(X1,X2,X3) = W1*X1 + W2*X2 + W3*X3 + b\n",
    "def hypothesis(X):\n",
    "    return   tf.matmul(X,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용 함수 : (Hx - y)^2 의 평균\n",
    "# tf.square() : 제곱\n",
    "# tf.reduce_mean() : 합의 평균\n",
    "def cost_func():\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis(x_train) - y_train))\n",
    "    return cost\n",
    "# reduce_mean : 차원을 1차원으로 축소해 평균을 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사 하강법\n",
    "# learning_rate(학습율) 을 0.01로 설정하여 optimizer 객체를 생성\n",
    "# optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "# optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "0000 cost: [ 65066.566 ] W: [[-0.17030665]\n",
      " [-0.9402863 ]\n",
      " [-0.02964049]] b: [0.23652864]\n",
      "0100 cost: [ 4095.1235 ] W: [[ 0.61485434]\n",
      " [-0.15491977]\n",
      " [ 0.7556198 ]] b: [1.0216748]\n",
      "0200 cost: [ 47.590633 ] W: [[0.85247976]\n",
      " [0.08370257]\n",
      " [0.99372613]] b: [1.2592261]\n",
      "0300 cost: [ 12.429815 ] W: [[0.8754433 ]\n",
      " [0.10827628]\n",
      " [1.0174667 ]] b: [1.2820694]\n",
      "0400 cost: [ 12.382455 ] W: [[0.87506783]\n",
      " [0.10988351]\n",
      " [1.0180485 ]] b: [1.2815446]\n",
      "0500 cost: [ 12.352392 ] W: [[0.87393206]\n",
      " [0.11105164]\n",
      " [1.0180255 ]] b: [1.2802325]\n",
      "0600 cost: [ 12.318477 ] W: [[0.8726458 ]\n",
      " [0.11237431]\n",
      " [1.0180017 ]] b: [1.2787429]\n",
      "0700 cost: [ 12.280793 ] W: [[0.87121135]\n",
      " [0.11384594]\n",
      " [1.0179778 ]] b: [1.2770784]\n",
      "0800 cost: [ 12.239459 ] W: [[0.86963135]\n",
      " [0.11546459]\n",
      " [1.017954  ]] b: [1.2752405]\n",
      "0900 cost: [ 12.194555 ] W: [[0.8679064 ]\n",
      " [0.11722923]\n",
      " [1.0179302 ]] b: [1.2732284]\n",
      "1000 cost: [ 12.146095 ] W: [[0.8660364 ]\n",
      " [0.11914004]\n",
      " [1.0179063 ]] b: [1.2710406]\n",
      "1100 cost: [ 12.094105 ] W: [[0.8640209 ]\n",
      " [0.12119789]\n",
      " [1.0178825 ]] b: [1.2686743]\n",
      "1200 cost: [ 12.038639 ] W: [[0.8618582]\n",
      " [0.1234042]\n",
      " [1.0178586]] b: [1.2661258]\n",
      "1300 cost: [ 11.979654 ] W: [[0.8595456 ]\n",
      " [0.12576072]\n",
      " [1.0178366 ]] b: [1.2633905]\n",
      "1400 cost: [ 11.917176 ] W: [[0.857078  ]\n",
      " [0.12826645]\n",
      " [1.0178221 ]] b: [1.2604599]\n",
      "1500 cost: [ 11.8512125 ] W: [[0.8544542]\n",
      " [0.1309257]\n",
      " [1.0178102]] b: [1.2573302]\n",
      "1600 cost: [ 11.7817545 ] W: [[0.8516728 ]\n",
      " [0.13374251]\n",
      " [1.0178015 ]] b: [1.253996]\n",
      "1700 cost: [ 11.708785 ] W: [[0.8487266 ]\n",
      " [0.13671601]\n",
      " [1.0178013 ]] b: [1.2504463]\n",
      "1800 cost: [ 11.632336 ] W: [[0.84561455]\n",
      " [0.1398519 ]\n",
      " [1.0178074 ]] b: [1.2466764]\n",
      "1900 cost: [ 11.5524025 ] W: [[0.8423317 ]\n",
      " [0.14315194]\n",
      " [1.0178211 ]] b: [1.2426766]\n",
      "2000 cost: [ 11.468972 ] W: [[0.8388733 ]\n",
      " [0.14661849]\n",
      " [1.017845  ]] b: [1.2384367]\n",
      "2100 cost: [ 11.382093 ] W: [[0.8352358 ]\n",
      " [0.15025511]\n",
      " [1.0178806 ]] b: [1.2339482]\n",
      "2200 cost: [ 11.291771 ] W: [[0.83141476]\n",
      " [0.15406464]\n",
      " [1.0179291 ]] b: [1.2292005]\n",
      "2300 cost: [ 11.198047 ] W: [[0.82740504]\n",
      " [0.15804946]\n",
      " [1.0179925 ]] b: [1.2241814]\n",
      "2400 cost: [ 11.100923 ] W: [[0.8232027 ]\n",
      " [0.16221263]\n",
      " [1.0180713 ]] b: [1.21888]\n",
      "2500 cost: [ 11.000489 ] W: [[0.81880355]\n",
      " [0.16655704]\n",
      " [1.0181694 ]] b: [1.2132841]\n",
      "2600 cost: [ 10.896816 ] W: [[0.8142028 ]\n",
      " [0.17108491]\n",
      " [1.0182873 ]] b: [1.2073805]\n",
      "2700 cost: [ 10.78995 ] W: [[0.8093959 ]\n",
      " [0.17579816]\n",
      " [1.018428  ]] b: [1.2011544]\n",
      "2800 cost: [ 10.679954 ] W: [[0.80437833]\n",
      " [0.18069889]\n",
      " [1.0185941 ]] b: [1.1945918]\n",
      "2900 cost: [ 10.566969 ] W: [[0.7991465 ]\n",
      " [0.18578875]\n",
      " [1.0187875 ]] b: [1.1876773]\n",
      "3000 cost: [ 10.451099 ] W: [[0.79369587]\n",
      " [0.19106907]\n",
      " [1.0190128 ]] b: [1.180394]\n",
      "3100 cost: [ 10.332492 ] W: [[0.78802305]\n",
      " [0.19654046]\n",
      " [1.0192717 ]] b: [1.172725]\n",
      "3200 cost: [ 10.211248 ] W: [[0.7821242 ]\n",
      " [0.20220341]\n",
      " [1.0195675 ]] b: [1.164652]\n",
      "3300 cost: [ 10.087582 ] W: [[0.7759964 ]\n",
      " [0.20805782]\n",
      " [1.0199047 ]] b: [1.1561562]\n",
      "3400 cost: [ 9.961646 ] W: [[0.7696366]\n",
      " [0.2141027]\n",
      " [1.0202861]] b: [1.147217]\n",
      "3500 cost: [ 9.8336525 ] W: [[0.76304257]\n",
      " [0.22033681]\n",
      " [1.0207157 ]] b: [1.1378134]\n",
      "3600 cost: [ 9.7038145 ] W: [[0.7562125 ]\n",
      " [0.22675797]\n",
      " [1.0211979 ]] b: [1.127923]\n",
      "3700 cost: [ 9.572372 ] W: [[0.74914515]\n",
      " [0.23336342]\n",
      " [1.0217366 ]] b: [1.1175226]\n",
      "3800 cost: [ 9.439592 ] W: [[0.74184   ]\n",
      " [0.24014968]\n",
      " [1.0223364 ]] b: [1.1065873]\n",
      "3900 cost: [ 9.305708 ] W: [[0.7342972 ]\n",
      " [0.24711215]\n",
      " [1.0230014 ]] b: [1.095091]\n",
      "4000 cost: [ 9.171061 ] W: [[0.7265178 ]\n",
      " [0.25424558]\n",
      " [1.0237367 ]] b: [1.0830071]\n",
      "4100 cost: [ 9.035935 ] W: [[0.7185036 ]\n",
      " [0.26154345]\n",
      " [1.0245467 ]] b: [1.0703056]\n",
      "4200 cost: [ 8.900622 ] W: [[0.7102576 ]\n",
      " [0.26899862]\n",
      " [1.0254363 ]] b: [1.0569566]\n",
      "4300 cost: [ 8.765508 ] W: [[0.70178354]\n",
      " [0.27660263]\n",
      " [1.02641   ]] b: [1.0429288]\n",
      "4400 cost: [ 8.630913 ] W: [[0.69308674]\n",
      " [0.2843461 ]\n",
      " [1.0274727 ]] b: [1.0281891]\n",
      "4500 cost: [ 8.497159 ] W: [[0.6841733]\n",
      " [0.2922184]\n",
      " [1.028629 ]] b: [1.012702]\n",
      "4600 cost: [ 8.364628 ] W: [[0.6750509 ]\n",
      " [0.30020767]\n",
      " [1.0298831 ]] b: [0.99643123]\n",
      "4700 cost: [ 8.233722 ] W: [[0.6657285 ]\n",
      " [0.30830145]\n",
      " [1.03124   ]] b: [0.9793375]\n",
      "4800 cost: [ 8.104747 ] W: [[0.65621656]\n",
      " [0.31648552]\n",
      " [1.0327029 ]] b: [0.9613804]\n",
      "4900 cost: [ 7.9780827 ] W: [[0.6465268 ]\n",
      " [0.32474506]\n",
      " [1.0342759 ]] b: [0.9425181]\n",
      "5000 cost: [ 7.8540983 ] W: [[0.6366728 ]\n",
      " [0.33306387]\n",
      " [1.035962  ]] b: [0.9227058]\n",
      "5100 cost: [ 7.7331 ] W: [[0.6266696 ]\n",
      " [0.34142482]\n",
      " [1.037764  ]] b: [0.90189725]\n",
      "5200 cost: [ 7.6154714 ] W: [[0.6165341 ]\n",
      " [0.34980983]\n",
      " [1.0396836 ]] b: [0.880044]\n",
      "5300 cost: [ 7.501462 ] W: [[0.6062845]\n",
      " [0.3581996]\n",
      " [1.0417224]] b: [0.8570945]\n",
      "5400 cost: [ 7.391428 ] W: [[0.5959412]\n",
      " [0.3665745]\n",
      " [1.0438809]] b: [0.8329976]\n",
      "5500 cost: [ 7.285581 ] W: [[0.58552563]\n",
      " [0.3749141 ]\n",
      " [1.0461586 ]] b: [0.8076965]\n",
      "5600 cost: [ 7.184164 ] W: [[0.5750614 ]\n",
      " [0.38319722]\n",
      " [1.0485541 ]] b: [0.7811346]\n",
      "5700 cost: [ 7.087414 ] W: [[0.5645731]\n",
      " [0.3914023]\n",
      " [1.0510647]] b: [0.75325274]\n",
      "5800 cost: [ 6.9954696 ] W: [[0.5540875]\n",
      " [0.3995079]\n",
      " [1.0536867]] b: [0.7239899]\n",
      "5900 cost: [ 6.9084387 ] W: [[0.5436317]\n",
      " [0.4074924]\n",
      " [1.0564158]] b: [0.69328284]\n",
      "6000 cost: [ 6.826429 ] W: [[0.5332345 ]\n",
      " [0.41533387]\n",
      " [1.0592456 ]] b: [0.6610666]\n",
      "6100 cost: [ 6.7494965 ] W: [[0.52292585]\n",
      " [0.4230118 ]\n",
      " [1.0621682 ]] b: [0.6272749]\n",
      "6200 cost: [ 6.6776414 ] W: [[0.5127359 ]\n",
      " [0.43050495]\n",
      " [1.0651755 ]] b: [0.5918395]\n",
      "6300 cost: [ 6.610788 ] W: [[0.50269574]\n",
      " [0.43779364]\n",
      " [1.0682579 ]] b: [0.55469173]\n",
      "6400 cost: [ 6.548887 ] W: [[0.4928368]\n",
      " [0.4448589]\n",
      " [1.0714042]] b: [0.51576096]\n",
      "6500 cost: [ 6.491812 ] W: [[0.48319054]\n",
      " [0.451684  ]\n",
      " [1.0746007 ]] b: [0.47497806]\n",
      "6600 cost: [ 6.439372 ] W: [[0.4737876 ]\n",
      " [0.45825264]\n",
      " [1.0778346 ]] b: [0.43227276]\n",
      "6700 cost: [ 6.391397 ] W: [[0.46465713]\n",
      " [0.46454978]\n",
      " [1.0810927 ]] b: [0.38757455]\n",
      "6800 cost: [ 6.34765 ] W: [[0.4558287]\n",
      " [0.4705635]\n",
      " [1.084359 ]] b: [0.34081486]\n",
      "6900 cost: [ 6.30786 ] W: [[0.44732866]\n",
      " [0.4762827 ]\n",
      " [1.0876199 ]] b: [0.2919269]\n",
      "7000 cost: [ 6.2717533 ] W: [[0.4391825]\n",
      " [0.4816995]\n",
      " [1.0908585]] b: [0.24084523]\n",
      "7100 cost: [ 6.239036 ] W: [[0.43141276]\n",
      " [0.4868077 ]\n",
      " [1.0940601 ]] b: [0.18750815]\n",
      "7200 cost: [ 6.209422 ] W: [[0.4240395 ]\n",
      " [0.49160305]\n",
      " [1.0972103 ]] b: [0.13185681]\n",
      "7300 cost: [ 6.1825433 ] W: [[0.41707966]\n",
      " [0.4960841 ]\n",
      " [1.1002939 ]] b: [0.07383699]\n",
      "7400 cost: [ 6.1581492 ] W: [[0.41054633]\n",
      " [0.5002521 ]\n",
      " [1.1032982 ]] b: [0.01339984]\n",
      "7500 cost: [ 6.135897 ] W: [[0.40444908]\n",
      " [0.50410974]\n",
      " [1.1062118 ]] b: [-0.04949814]\n",
      "7600 cost: [ 6.1155186 ] W: [[0.3987935]\n",
      " [0.5076625]\n",
      " [1.1090238]] b: [-0.11489377]\n",
      "7700 cost: [ 6.0967293 ] W: [[0.39358175]\n",
      " [0.5109184 ]\n",
      " [1.1117253 ]] b: [-0.18281561]\n",
      "7800 cost: [ 6.079287 ] W: [[0.38881117]\n",
      " [0.5138868 ]\n",
      " [1.1143094 ]] b: [-0.25328445]\n",
      "7900 cost: [ 6.062945 ] W: [[0.3844755 ]\n",
      " [0.51657975]\n",
      " [1.116771  ]] b: [-0.3263117]\n",
      "8000 cost: [ 6.0475063 ] W: [[0.38056424]\n",
      " [0.5190099 ]\n",
      " [1.1191077 ]] b: [-0.40189934]\n",
      "8100 cost: [ 6.0327883 ] W: [[0.37706316]\n",
      " [0.52119213]\n",
      " [1.1213188 ]] b: [-0.48003876]\n",
      "8200 cost: [ 6.0186615 ] W: [[0.3739549 ]\n",
      " [0.52314234]\n",
      " [1.1234051 ]] b: [-0.5607098]\n",
      "8300 cost: [ 6.0050306 ] W: [[0.37121826]\n",
      " [0.5248768 ]\n",
      " [1.1253715 ]] b: [-0.64388156]\n",
      "8400 cost: [ 5.9917183 ] W: [[0.36883053]\n",
      " [0.5264134 ]\n",
      " [1.127222  ]] b: [-0.7295097]\n",
      "8500 cost: [ 5.9787307 ] W: [[0.3667658]\n",
      " [0.5277692]\n",
      " [1.1289636]] b: [-0.8175377]\n",
      "8600 cost: [ 5.9659705 ] W: [[0.36499673]\n",
      " [0.5289621 ]\n",
      " [1.1306052 ]] b: [-0.9078967]\n",
      "8700 cost: [ 5.9534407 ] W: [[0.36349633]\n",
      " [0.5300099 ]\n",
      " [1.1321543 ]] b: [-1.0005019]\n",
      "8800 cost: [ 5.941083 ] W: [[0.36223572]\n",
      " [0.53092974]\n",
      " [1.1336218 ]] b: [-1.0952564]\n",
      "8900 cost: [ 5.928951 ] W: [[0.36118764]\n",
      " [0.531738  ]\n",
      " [1.1350162 ]] b: [-1.1920491]\n",
      "9000 cost: [ 5.917012 ] W: [[0.36032423]\n",
      " [0.5324502 ]\n",
      " [1.136348  ]] b: [-1.290753]\n",
      "9100 cost: [ 5.905311 ] W: [[0.35961974]\n",
      " [0.5330807 ]\n",
      " [1.1376266 ]] b: [-1.3912269]\n",
      "9200 cost: [ 5.893832 ] W: [[0.35904992]\n",
      " [0.5336428 ]\n",
      " [1.1388605 ]] b: [-1.4933151]\n",
      "9300 cost: [ 5.8826494 ] W: [[0.35859236]\n",
      " [0.534148  ]\n",
      " [1.140058  ]] b: [-1.5968462]\n",
      "9400 cost: [ 5.87175 ] W: [[0.35822737]\n",
      " [0.5346074 ]\n",
      " [1.1412258 ]] b: [-1.7016326]\n",
      "9500 cost: [ 5.8611913 ] W: [[0.35793698]\n",
      " [0.53503   ]\n",
      " [1.1423696 ]] b: [-1.8074744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600 cost: [ 5.850982 ] W: [[0.35770532]\n",
      " [0.535423  ]\n",
      " [1.1434957 ]] b: [-1.9141546]\n",
      "9700 cost: [ 5.841175 ] W: [[0.35752  ]\n",
      " [0.5357934]\n",
      " [1.1446053]] b: [-2.021443]\n",
      "9800 cost: [ 5.83179 ] W: [[0.3573701]\n",
      " [0.5361461]\n",
      " [1.1457027]] b: [-2.129092]\n",
      "9900 cost: [ 5.8228264 ] W: [[0.35724655]\n",
      " [0.536485  ]\n",
      " [1.1467894 ]] b: [-2.236848]\n",
      "10000 cost: [ 5.8143287 ] W: [[0.35714284]\n",
      " [0.5368133 ]\n",
      " [1.1478648 ]] b: [-2.3444374]\n",
      "***** Learning Finished\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "print('***** Start Learning!!')\n",
    "for step in range(10001):\n",
    "    # cost를 minimize한다\n",
    "    optimizer.minimize(cost_func,var_list=[W,b])\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print('%04d'%step,'cost: [',cost_func().numpy(),']',\n",
    "             'W:',W.numpy(),'b:',b.numpy())\n",
    "\n",
    "print('***** Learning Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight : [[0.35714284]\n",
      " [0.5368133 ]\n",
      " [1.1478648 ]]\n",
      "Bias: [-2.3444374]\n"
     ]
    }
   ],
   "source": [
    "# 회귀 계수 : weight과 bias출력\n",
    "print('Weight :',W.numpy())\n",
    "print('Bias:',b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Predict\n",
      "[[152.76192]\n",
      " [184.86086]\n",
      " [181.59912]\n",
      " [199.33546]\n",
      " [139.50722]]\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "print('***** Predict')\n",
    "x_data = [[73.,80.,75.],\n",
    "          [93.,88.,93.],\n",
    "          [89.,91.,90.],\n",
    "          [96.,98.,100.],\n",
    "          [73.,66.,70.]]\n",
    "x_test = np.array(x_data,dtype=np.float32)\n",
    "print(hypothesis(x_test).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.4112918\n"
     ]
    }
   ],
   "source": [
    "# 정확도 측정\n",
    "def get_rmse(y_test,preds):\n",
    "    squared_error = 0\n",
    "    for k,_ in enumerate(y_test):\n",
    "        squared_error += (preds[k] - y_test[k])**2\n",
    "    mse = squared_error/len(y_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse[0]\n",
    "\n",
    "# # 학습한 데이터를 그래도 검증데이터로 사용한 경우\n",
    "# x_test = x_train\n",
    "# y_test = y_train\n",
    "\n",
    "# preds = hypothesis(x_test).numpy()\n",
    "print('RMSE:',get_rmse(y_test,preds))  # RMSE: 2.4112918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
