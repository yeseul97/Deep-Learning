{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax_multi_classification\n",
    "# multi-nomial Classification (다중 분류) : Y값의 범주가 3개 이상인 분류\n",
    "# 활성화 함수(Activation function) 으로 softmax()가 사용 된다\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.random.set_seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 16)\n",
      "(70, 1)\n",
      "(31, 16)\n",
      "(31, 1)\n",
      "float32 float32\n",
      "int32 int32\n"
     ]
    }
   ],
   "source": [
    "# 데이터 가져오기\n",
    "xy = np.loadtxt('data-04-zoo.csv',delimiter=',',dtype=np.float32)\n",
    "\n",
    "# 학습 데이터 : 70%, 70개\n",
    "x_train = xy[:70,:-1]\n",
    "y_data = xy[:70,[-1]]\n",
    "y_train = y_data.astype('int32')  # one-hot 인코딩을 위해 반드시 int형으로 사용\n",
    "print(x_train.shape)  # (70,16)\n",
    "print(y_train.shape)  #(70,1)\n",
    "\n",
    "# 검증 데이터 : 30%, 31개\n",
    "x_test = xy[70:,:-1]\n",
    "y_data2 = xy[70:,[-1]]\n",
    "y_test = y_data2.astype('int32')   # one-hot 인코딩을 위해 반드시 int형으로 사용\n",
    "print(x_test.shape)  # (31,16)\n",
    "print(y_test.shape)  #(31,1)\n",
    "print(x_train.dtype,x_test.dtype)\n",
    "print(y_train.dtype,y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 1, 7)\n",
      "(70, 7)\n"
     ]
    }
   ],
   "source": [
    "# one-hot 인코딩\n",
    "nb_classes = 7  # 분류 class의 갯수(0~6)\n",
    "Y_one_hot = tf.one_hot(y_train,nb_classes)  # [None,1,7]\n",
    "print(Y_one_hot.shape)                      #[70,1,7], Rank=3 (3차원)\n",
    "Y_one_hot = tf.reshape(Y_one_hot,[-1,nb_classes])\n",
    "print(Y_one_hot.shape)                      # [70,7], Rank=2 (2차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 초기화 : weight, bias\n",
    "# (70,16) *(16,7) = (70,7)\n",
    "nb_classes = 7  # 분류 갯수\n",
    "\n",
    "W = tf.Variable(tf.random.normal([16,nb_classes]), name ='weight')\n",
    "b = tf.Variable(tf.random.normal([nb_classes]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis 예측 함수 : H(X) = softmax(W*X + b)\n",
    "def logits(X):\n",
    "    return tf.matmul(X,W) + b\n",
    "\n",
    "def hypothesis(X):\n",
    "    return   tf.nn.softmax(logits(X))\n",
    "# 위 함수 반환값을 아래 함수에서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용 함수 구현 방법 2 : tf.nn.softmax_cross_entropy_with_logits() 함수 사용\n",
    "def cost_func():\n",
    "    cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits(x_train),\n",
    "                                                     labels=Y_one_hot)\n",
    "    cost = tf.reduce_mean(cost_i)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사 하강법\n",
    "# learning_rate(학습율) 을 0.01로 설정하여 optimizer 객체를 생성\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "0000 cost: [ 3.364605 ]\n",
      "1000 cost: [ 0.0032419092 ]\n",
      "2000 cost: [ 0.0009893123 ]\n",
      "3000 cost: [ 0.00044815178 ]\n",
      "4000 cost: [ 0.00023481257 ]\n",
      "5000 cost: [ 0.00013186333 ]\n",
      "***** Learning Finished\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "print('***** Start Learning!!')\n",
    "for step in range(5001):\n",
    "    # cost를 minimize한다\n",
    "    optimizer.minimize(cost_func,var_list=[W,b])\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "        print('%04d'%step,'cost: [',cost_func().numpy(),']')\n",
    "        \n",
    "print('***** Learning Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight : [[ 50.305054  38.481403  49.102955  48.55165   47.386562  45.24111\n",
      "   47.244205]\n",
      " [ 44.422176  55.902668  46.48745   48.136486  46.402138  45.45441\n",
      "   44.485523]\n",
      " [ 46.65957   47.61995   49.68914   52.743843  50.979492  50.671906\n",
      "   52.682156]\n",
      " [-49.219154 -49.281418 -54.504124 -54.825558 -54.915813 -50.94095\n",
      "  -57.69752 ]\n",
      " [ 48.408752  49.857864  45.55915   48.404934  45.902523  51.01263\n",
      "   44.26856 ]\n",
      " [ 48.095367  48.9789    45.45107   53.3811    51.20776   46.188877\n",
      "   52.60581 ]\n",
      " [ 50.219772  49.36512   49.16879   47.69735   50.69365   48.032433\n",
      "   52.679306]\n",
      " [ 51.410393  47.37609   49.91512   50.776722  52.77001   48.867798\n",
      "   46.30844 ]\n",
      " [ 51.618153  49.975452  52.61507   49.982723  52.730465  48.777664\n",
      "   46.111492]\n",
      " [ 50.96331   50.546646  52.38328   45.86567   48.776855  48.84697\n",
      "   41.655403]\n",
      " [ 48.14555   48.796326  51.99006   48.442303  49.943752  49.29761\n",
      "   46.938416]\n",
      " [ 49.480103  49.118008  45.47159   52.46855   44.720966  48.81852\n",
      "   47.04557 ]\n",
      " [ 49.992184  50.784233  45.686787  48.041355  51.140278  51.900833\n",
      "   50.87606 ]\n",
      " [ 49.755383  52.11727   52.123085  52.45672   49.03586   48.62777\n",
      "   47.629734]\n",
      " [ 50.925816  50.54015   48.593964  50.95117   49.142143  48.88328\n",
      "   47.22267 ]\n",
      " [ 51.173824  47.04389   46.651676  48.688095  46.37661   46.937798\n",
      "   49.597374]]\n",
      "Bias: [50.81696  50.090042 51.283676 49.386086 46.122612 50.267216 52.371338]\n"
     ]
    }
   ],
   "source": [
    "# 회귀 계수 : weight과 bias출력\n",
    "print('Weight :',W.numpy())\n",
    "print('Bias:',b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 1, 7)\n",
      "(31, 7)\n",
      "Accuracy: 0.83870965\n",
      "***** Predict\n",
      "[True] Prediction: 0 / Real Y: 0\n",
      "[True] Prediction: 1 / Real Y: 1\n",
      "[False] Prediction: 5 / Real Y: 6\n",
      "[True] Prediction: 3 / Real Y: 3\n",
      "[True] Prediction: 0 / Real Y: 0\n",
      "[True] Prediction: 0 / Real Y: 0\n",
      "[True] Prediction: 2 / Real Y: 2\n",
      "[True] Prediction: 6 / Real Y: 6\n",
      "[True] Prediction: 1 / Real Y: 1\n",
      "[True] Prediction: 1 / Real Y: 1\n",
      "[True] Prediction: 2 / Real Y: 2\n",
      "[False] Prediction: 2 / Real Y: 6\n",
      "[True] Prediction: 3 / Real Y: 3\n",
      "[True] Prediction: 1 / Real Y: 1\n",
      "[True] Prediction: 0 / Real Y: 0\n",
      "[True] Prediction: 6 / Real Y: 6\n",
      "[True] Prediction: 3 / Real Y: 3\n",
      "[True] Prediction: 1 / Real Y: 1\n",
      "[True] Prediction: 5 / Real Y: 5\n",
      "[True] Prediction: 4 / Real Y: 4\n",
      "[False] Prediction: 5 / Real Y: 2\n",
      "[False] Prediction: 4 / Real Y: 2\n",
      "[True] Prediction: 3 / Real Y: 3\n",
      "[True] Prediction: 0 / Real Y: 0\n",
      "[True] Prediction: 0 / Real Y: 0\n",
      "[True] Prediction: 1 / Real Y: 1\n",
      "[True] Prediction: 0 / Real Y: 0\n",
      "[True] Prediction: 5 / Real Y: 5\n",
      "[True] Prediction: 0 / Real Y: 0\n",
      "[False] Prediction: 2 / Real Y: 6\n",
      "[True] Prediction: 1 / Real Y: 1\n"
     ]
    }
   ],
   "source": [
    "# 정확도 평가 : accuracy computation\n",
    "# 학습과 검증데이터를 별도로 사용한 경우 (70%:30%)\n",
    "\n",
    "# y_test 값의 one-hot 인코딩\n",
    "Y_one_hot = tf.one_hot(y_test,nb_classes)  # [None,1,7]\n",
    "print(Y_one_hot.shape)                     # [31,1,7], Rank=3 (3차원)\n",
    "Y_one_hot = tf.reshape(Y_one_hot,[-1,nb_classes])\n",
    "print(Y_one_hot.shape)                     # [31,7], Rank=2 (2차원)\n",
    "\n",
    "def predict(X):\n",
    "    return tf.argmax(hypothesis(X),1) \n",
    "\n",
    "correct_predict = tf.equal(predict(x_test),tf.argmax(Y_one_hot,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predict, dtype = tf.float32))\n",
    "\n",
    "print(\"Accuracy:\",accuracy.numpy()) # Accuracy: 0.8064516\n",
    "\n",
    "print('***** Predict')\n",
    "pred = predict(x_test).numpy()\n",
    "for p,y in zip(pred, y_test.flatten()):\n",
    "    print(\"[{}] Prediction: {} / Real Y: {}\".format(p == int(y), p, int(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
